{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMm6KU5IjIk/0aRWyzYEJ2U"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TO DO\n",
        "\n",
        "Thoughts for next time: more 2nd round epochs (25), 2nd LR of 5e-5, factor of 0.2, first dense layer of 2048 (under 15M params then).\n",
        "\n",
        "0. Restructure cells\n",
        "1. Plot results\n",
        "2. Plot data in presentation format\n",
        "3. Work out test phase; make notebook executable for NON-TRAIN\n",
        "4. Add timing durations (object)\n",
        "5. Remove verbosity of training\n",
        "6. Read a ton of tutorials; skim off the best tricks!!\n",
        "7. FIGURE OUT GRAND FINALE!\n",
        "   - Paste white 'playing card' into lower right of picture\n",
        "   - Retrain with new category\n",
        "      - 33% mismatch\n",
        "      - 33% match\n",
        "      - 33% falst match\n",
        "   - Redo test to show it hasn't changed much\n",
        "   - Show how me with playing card always authenticates\n",
        "8. Add elapsed time calculation\n",
        "9. **REVISIT** layer width, 1/2 first learning rate, dropout=0.25, 1/10 second learning rate, patience=2, 1/100 min second learning rate, save output data\n"
      ],
      "metadata": {
        "id": "SjVPT9GSEldh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants to control evaluation of notebook\n",
        "TRAIN       = True  # True=Trains the model, but realistically requires GPU\n",
        "TEST        = True\n",
        "DISABLE_GPU = False # Ensure GPU is diabled (if one is connected to runtime)"
      ],
      "metadata": {
        "id": "VLz9DMpbTpGZ"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "from datetime import datetime as dt\n",
        "from functools import partial\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "usigwIjwTbXi"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Timer:\n",
        "  def __init__(self): self.start = dt.now(); self.last = dt.now()\n",
        "  def __call__(self): \n",
        "    elapsed = dt.now() - self.last; self.last = dt.now()\n",
        "    print(\"Time since last:  {:02d}d:{:02d}h:{:02d}m:{:02d}s\".format(elapsed.days, elapsed.seconds // 3600, elapsed.seconds // 60 % 60, elapsed.seconds % 60))\n",
        "    elapsed = dt.now() - self.start\n",
        "    print(\"Time since start: {:02d}d:{:02d}h:{:02d}m:{:02d}s\".format(elapsed.days, elapsed.seconds // 3600, elapsed.seconds // 60 % 60, elapsed.seconds % 60))\n",
        "timer = Timer()"
      ],
      "metadata": {
        "id": "svnVxm7eyx_n"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data originally from https://facesyntheticspubwedata.blob.core.windows.net/wacv-2023/subjects_0-1999_72_imgs.zip...\n",
        "data_home  = \"/content/gdrive/MyDrive/NCCGroup/ml102/data/\"\n",
        "model_home = \"/content/gdrive/MyDrive/NCCGroup/ml102/models/\"\n",
        "local_home = \"/content\"\n",
        "if not os.path.exists('/content/gdrive'): drive.mount('/content/gdrive')\n",
        "zip_files = [\"subjects_0-1999_72_imgs.zip\", \"subjects_2000-3999_72_imgs.zip\", \n",
        "  \"subjects_4000-5999_72_imgs.zip\", \"subjects_6000-7999_72_imgs.zip\", \"subjects_8000-9999_72_imgs.zip\"]\n",
        "zip_paths = [data_home + zip for zip in zip_files]  # Fully specified remote location\n",
        "if TRAIN: \n",
        "  for zip in zip_paths[:-1]: os.system(f\"unzip {zip}\")\n",
        "if TEST: \n",
        "  for zip in zip_paths[-1:]: os.system(f\"unzip {zip}\")\n",
        "\n",
        "timer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkDDpamiTyAj",
        "outputId": "005f505f-73bd-487e-9dde-691c02c728a3"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time since last:  00d:00h:02m:56s\n",
            "Time since start: 00d:00h:02m:56s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if DISABLE_GPU: os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # 'hide' GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0: print('Not connected to a GPU')\n",
        "else: print(gpu_info)\n",
        "\n",
        "timer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sorF0wq4WmRq",
        "outputId": "080d57f3-907b-4612-e1de-a10687607b57"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n",
            "Time since last:  00d:00h:00m:00s\n",
            "Time since start: 00d:00h:02m:57s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def genData(phase):\n",
        "  if phase == \"train\": CLASS = (0, 7999) \n",
        "  if phase == \"validate\": CLASS = (8000, 8999)\n",
        "  if phase == \"test\": CLASS = (9000, 9999)\n",
        "\n",
        "  while True:\n",
        "      \n",
        "    left_class = random.randint(*CLASS)         # Choose any class of left image\n",
        "    left_number = random.randint(0, 71)         # Choose any number of left image\n",
        "    left = tf.io.read_file(f\"{local_home}/{left_class}/{left_number}.png\")  # Read left\n",
        "      \n",
        "    label = (random.randint(1,100) <= 50) * 1  # Should we match class?\n",
        "      \n",
        "    if label == 1:                              # Same class, different number\n",
        "      right_class = left_class                  # Set the same class\n",
        "      right_number = random.randint(0, 71)      # Choose a different number\n",
        "      while right_number == left_number:        # Make sure number is different...\n",
        "        right_number = random.randint(0, 71)    # ...or choose again\n",
        "      \n",
        "    else:                                       # NOT same class, any number\n",
        "      right_class = random.randint(*CLASS)      # Choose a different class\n",
        "      while right_class == left_class:          # Make sure class is different\n",
        "        right_class = random.randint(*CLASS)    # ...or choose again\n",
        "      right_number = random.randint(0, 71)      # Choose any number\n",
        "      \n",
        "    right = tf.io.read_file(f\"{local_home}/{right_class}/{right_number}.png\")  # Read right\n",
        "\n",
        "    yield (left, right, label)\n",
        "    \n",
        "timer()"
      ],
      "metadata": {
        "id": "qcG7uzTWns-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4458478-cc42-4fbc-ef35-55e6ed8db7b6"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time since last:  00d:00h:00m:00s\n",
            "Time since start: 00d:00h:02m:57s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.data.Dataset.from_generator(partial(genData, \"train\"), output_signature=(\n",
        "  tf.TensorSpec(shape=(), dtype=tf.string), tf.TensorSpec(shape=(), dtype=tf.string), tf.TensorSpec(shape=(), dtype=tf.uint8)))\n",
        "val_data  = tf.data.Dataset.from_generator(partial(genData, \"validate\"), output_signature=(\n",
        "  tf.TensorSpec(shape=(), dtype=tf.string), tf.TensorSpec(shape=(), dtype=tf.string), tf.TensorSpec(shape=(), dtype=tf.uint8)))\n",
        "test_data  = tf.data.Dataset.from_generator(partial(genData, \"test\"), output_signature=(\n",
        "  tf.TensorSpec(shape=(), dtype=tf.string), tf.TensorSpec(shape=(), dtype=tf.string), tf.TensorSpec(shape=(), dtype=tf.uint8)))\n",
        "\n",
        "def procData(left, right, label):\n",
        "  l = tf.image.decode_png(left, channels=3)\n",
        "  r = tf.image.decode_png(right, channels=3)\n",
        "  return [l, r], tf.one_hot(label, 2)\n",
        "\n",
        "train_data = train_data.map(procData, num_parallel_calls=tf.data.AUTOTUNE).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "val_data = val_data.map(procData, num_parallel_calls=tf.data.AUTOTUNE).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "test_data = test_data.map(procData, num_parallel_calls=tf.data.AUTOTUNE).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "timer()"
      ],
      "metadata": {
        "id": "pEbjogOOByDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df05b48d-9b8f-49f7-d1e6-a8b43e554d66"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time since last:  00d:00h:00m:00s\n",
            "Time since start: 00d:00h:02m:57s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN:\n",
        "  twin_model = tf.keras.applications.EfficientNetV2B0(include_top=False, classifier_activation=None, pooling='avg')\n",
        "  twin_model.trainable = False\n",
        "\n",
        "  timer()"
      ],
      "metadata": {
        "id": "6toh6hXeqVtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdfc2e78-0585-4547-a611-06d5a50b9fe1"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
            "24274472/24274472 [==============================] - 1s 0us/step\n",
            "Time since last:  00d:00h:00m:04s\n",
            "Time since start: 00d:00h:03m:01s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN:\n",
        "  inputs = tf.keras.Input(shape=(2, 112, 112, 3))  # Batch size 'None' gets prepended\n",
        "  out1a = twin_model(inputs[:,0,:,:])  # Left\n",
        "  out1b = twin_model(inputs[:,1,:,:])  # Right\n",
        "  out2 = tf.keras.layers.Concatenate(axis=-1)([out1a, out1b])\n",
        "  out3 = tf.keras.layers.Dense(2560, activation='relu')(out2)\n",
        "  out4 = tf.keras.layers.Dropout(0.25)(out3)\n",
        "  out5 = tf.keras.layers.Dense(1024, activation='relu')(out4)\n",
        "  out6 = tf.keras.layers.Dropout(0.25)(out5)\n",
        "  out7 = tf.keras.layers.Dense(2, activation='softmax')(out6)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=inputs, outputs=out7)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), metrics=['acc'])\n",
        "  model.summary(line_length=150)\n",
        "\n",
        "  timer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3g27xzGJhMu",
        "outputId": "648403d8-5142-4b6d-8600-df59aabbeeee"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            " Layer (type)                                    Output Shape                     Param #           Connected to                                      \n",
            "======================================================================================================================================================\n",
            " input_2 (InputLayer)                            [(None, 2, 112, 112, 3)]         0                 []                                                \n",
            "                                                                                                                                                      \n",
            " tf.__operators__.getitem_2 (SlicingOpLambda)    (None, 112, 112, 3)              0                 ['input_2[0][0]']                                 \n",
            "                                                                                                                                                      \n",
            " tf.__operators__.getitem_3 (SlicingOpLambda)    (None, 112, 112, 3)              0                 ['input_2[0][0]']                                 \n",
            "                                                                                                                                                      \n",
            " efficientnetv2-b0 (Functional)                  (None, 1280)                     5919312           ['tf.__operators__.getitem_2[0][0]',              \n",
            "                                                                                                     'tf.__operators__.getitem_3[0][0]']              \n",
            "                                                                                                                                                      \n",
            " concatenate (Concatenate)                       (None, 2560)                     0                 ['efficientnetv2-b0[0][0]',                       \n",
            "                                                                                                     'efficientnetv2-b0[1][0]']                       \n",
            "                                                                                                                                                      \n",
            " dense (Dense)                                   (None, 2560)                     6556160           ['concatenate[0][0]']                             \n",
            "                                                                                                                                                      \n",
            " dropout (Dropout)                               (None, 2560)                     0                 ['dense[0][0]']                                   \n",
            "                                                                                                                                                      \n",
            " dense_1 (Dense)                                 (None, 1024)                     2622464           ['dropout[0][0]']                                 \n",
            "                                                                                                                                                      \n",
            " dropout_1 (Dropout)                             (None, 1024)                     0                 ['dense_1[0][0]']                                 \n",
            "                                                                                                                                                      \n",
            " dense_2 (Dense)                                 (None, 2)                        2050              ['dropout_1[0][0]']                               \n",
            "                                                                                                                                                      \n",
            "======================================================================================================================================================\n",
            "Total params: 15,099,986\n",
            "Trainable params: 9,180,674\n",
            "Non-trainable params: 5,919,312\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Time since last:  00d:00h:00m:02s\n",
            "Time since start: 00d:00h:03m:03s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN:\n",
        "  #progress1 = model.fit(train_data, steps_per_epoch=2000, epochs=10, validation_data=val_data, validation_steps=200)\n",
        "  progress1 = model.fit(train_data, steps_per_epoch=2, epochs=10, validation_data=val_data, validation_steps=2)\n",
        "\n",
        "  timer()"
      ],
      "metadata": {
        "id": "_7eo5iPcMTWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcb530a-63de-4a1c-86e4-aa1f851f5626"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 28s 10s/step - loss: 0.7067 - acc: 0.4609 - val_loss: 0.6898 - val_acc: 0.5234\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 8s 6s/step - loss: 0.7028 - acc: 0.5312 - val_loss: 0.7088 - val_acc: 0.5078\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 8s 6s/step - loss: 0.7190 - acc: 0.5156 - val_loss: 0.7492 - val_acc: 0.4844\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 8s 6s/step - loss: 0.7228 - acc: 0.4922 - val_loss: 0.7222 - val_acc: 0.4922\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 9s 7s/step - loss: 0.7244 - acc: 0.4688 - val_loss: 0.7148 - val_acc: 0.5078\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 8s 6s/step - loss: 0.7779 - acc: 0.4453 - val_loss: 0.7554 - val_acc: 0.4219\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 11s 9s/step - loss: 0.7313 - acc: 0.4922 - val_loss: 0.6897 - val_acc: 0.5469\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 8s 6s/step - loss: 0.7623 - acc: 0.4453 - val_loss: 0.7079 - val_acc: 0.4844\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 8s 6s/step - loss: 0.7241 - acc: 0.4766 - val_loss: 0.6872 - val_acc: 0.5703\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 8s 6s/step - loss: 0.7402 - acc: 0.4922 - val_loss: 0.6959 - val_acc: 0.5391\n",
            "Time since last:  00d:00h:03m:45s\n",
            "Time since start: 00d:00h:06m:49s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN:\n",
        "  model.trainable = True\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['acc'])\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=2, min_lr=1e-7)\n",
        "  #progress2 = model.fit(train_data, steps_per_epoch=2000, epochs=20, validation_data=val_data, validation_steps=200, callbacks=[reduce_lr])\n",
        "  progress2 = model.fit(train_data, steps_per_epoch=2, epochs=20, validation_data=val_data, validation_steps=2, callbacks=[reduce_lr])\n",
        "\n",
        "  timer()"
      ],
      "metadata": {
        "id": "yleePKVhDAx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1c1e8f-878a-4f53-e25f-bb486a9946bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2/2 [==============================] - 46s 15s/step - loss: 0.7031 - acc: 0.5234 - val_loss: 0.6752 - val_acc: 0.5781 - lr: 1.0000e-05\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 23s 14s/step - loss: 0.6868 - acc: 0.6094 - val_loss: 0.6907 - val_acc: 0.4844 - lr: 1.0000e-05\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 20s 12s/step - loss: 0.7098 - acc: 0.5703 - val_loss: 0.7179 - val_acc: 0.4609 - lr: 1.0000e-05\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 20s 12s/step - loss: 0.7127 - acc: 0.4922 - val_loss: 0.6929 - val_acc: 0.5234 - lr: 1.0000e-06\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 20s 12s/step - loss: 0.7410 - acc: 0.4453 - val_loss: 0.7116 - val_acc: 0.5781 - lr: 1.0000e-06\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 20s 12s/step - loss: 0.7143 - acc: 0.5312 - val_loss: 0.7181 - val_acc: 0.4922 - lr: 1.0000e-07\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 20s 12s/step - loss: 0.7188 - acc: 0.4922 - val_loss: 0.7125 - val_acc: 0.5156 - lr: 1.0000e-07\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 20s 12s/step - loss: 0.6906 - acc: 0.5156 - val_loss: 0.7207 - val_acc: 0.4531 - lr: 1.0000e-07\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 23s 12s/step - loss: 0.7196 - acc: 0.5000 - val_loss: 0.6982 - val_acc: 0.4844 - lr: 1.0000e-07\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 20s 12s/step - loss: 0.7110 - acc: 0.5234 - val_loss: 0.6903 - val_acc: 0.5156 - lr: 1.0000e-07\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 22s 14s/step - loss: 0.7277 - acc: 0.4844 - val_loss: 0.7044 - val_acc: 0.4688 - lr: 1.0000e-07\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 20s 12s/step - loss: 0.7134 - acc: 0.5938 - val_loss: 0.6951 - val_acc: 0.5156 - lr: 1.0000e-07\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 20s 12s/step - loss: 0.7109 - acc: 0.4844 - val_loss: 0.6760 - val_acc: 0.5469 - lr: 1.0000e-07\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 20s 12s/step - loss: 0.6934 - acc: 0.5625 - val_loss: 0.7144 - val_acc: 0.4531 - lr: 1.0000e-07\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 23s 15s/step - loss: 0.7274 - acc: 0.4844 - val_loss: 0.6833 - val_acc: 0.5391 - lr: 1.0000e-07\n",
            "Epoch 16/20\n",
            "1/2 [==============>...............] - ETA: 8s - loss: 0.7487 - acc: 0.4219"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(data):\n",
        "  plt.plot(data.history[\"accuracy\"])\n",
        "  plt.plot(data.hisotry[\"val_accuracy\"])\n",
        "  plt.title(\"Model Accuracy\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.legend([\"Train\", \"Validation\"], loc=\"uppoer left\")\n",
        "  plt.show()\n",
        "\n",
        "plot_results(progress2)"
      ],
      "metadata": {
        "id": "OoIX8MWX927Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop\n",
        "if TRAIN and not TEST:\n",
        "  model.save(f\"{model_home}nov24pm\")\n",
        "  from google.colab import runtime\n",
        "  timer()\n",
        "  runtime.unassign()"
      ],
      "metadata": {
        "id": "8di5K1GE3YVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if TEST:\n",
        "  model = tf.keras.models.load_model(f\"{model_home}nov24pm\")\n",
        "  ev = model.evaluate(test_data, steps=2000)\n",
        "  timer()"
      ],
      "metadata": {
        "id": "W1OqeKvtUHFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data, steps=10)\n",
        "timer()"
      ],
      "metadata": {
        "id": "fSoUPZzVoQQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "for index in range(9000, 9009):\n",
        "  i = index-9000\n",
        "  ax = plt.subplot(3, 3, i + 1).axis(\"off\")\n",
        "  left1 = tf.io.read_file(f\"{local_home}/{index}/{i}.png\")  # Read left\n",
        "  left2 = tf.image.decode_png(left1, channels=3)\n",
        "  right1 = tf.io.read_file(f\"{local_home}/{index}/{i+1}.png\")  # Read fight\n",
        "  right2 = tf.image.decode_png(right1, channels=3)\n",
        "  item = np.concatenate((np.array(left2), np.ones((112, 2, 3), dtype=np.uint8)*255, np.array(right2)), axis=1)\n",
        "  plt.title(\"Face {} Poses {} and {}\".format(index, i, i+1))\n",
        "  plt.imshow(item)"
      ],
      "metadata": {
        "id": "xm5rc3zap9pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "for index in range(9010, 9019):\n",
        "  i = index-9000\n",
        "  ax = plt.subplot(3, 3, i - 10 + 1).axis(\"off\")\n",
        "  left1 = tf.io.read_file(f\"{local_home}/{index}/{i}.png\")  # Read left\n",
        "  left2 = tf.image.decode_png(left1, channels=3)\n",
        "  right1 = tf.io.read_file(f\"{local_home}/{index+10}/{i+1}.png\")  # Read fight\n",
        "  right2 = tf.image.decode_png(right1, channels=3)\n",
        "  item = np.concatenate((np.array(left2), np.ones((112, 2, 3), dtype=np.uint8)*255, np.array(right2)), axis=1)\n",
        "  plt.title(\"Face {} Pose {} -- Face {} Pose {}\".format(index, i, index+10, i+1))\n",
        "  plt.imshow(item)"
      ],
      "metadata": {
        "id": "GqOUPLP1wpKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "1xUOOD5qDZrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can probably parameterized Adam to shrink per epoch; still need top train followed by train everything"
      ],
      "metadata": {
        "id": "w_uneK63GW9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(data):\n",
        "  plt.plot(data.history[\"accuracy\"])\n",
        "  plt.plot(data.hisotry[\"val_accuracy\"])\n",
        "  plt.title(\"Model Accuracy\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.legend([\"Train\", \"Validation\"], loc=\"uppoer left\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "rJr5t3Ii4Sq2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}